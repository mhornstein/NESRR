The data_extractor.py script
============================
The data_extractor.py script loads the preprocessed WikiText-103 data, extracts its named entities and generates the required dataset.

How to run the script?
======================
In the cmd, write: python data_extractor.py <path to the preprocessed data file>.
for example: python data_extractor.py C:\Users\User\Documents\processed_data.txt

In general, the processed_data.txt is expected to be a text file where each line consists of a paragraph representing one or more sentences.

Script output
=============
* The progress and data measurements will be logged to the console.
* original_data_stats directory will be created with csv files and plots of stats of the complete data.
* sampled_data_stats directory will be created with csv files and plots of stats of the sampled data (as sampled for the final dataset).
* The sampled dataset will be created under the file 'data.csv'

More configurations
===================
One can further adjust other script parameters by updating the K, N_PROCESS, TEXT_BATCH_SIZE, N and DATASET_FILE constants.
Their roles are documented in the script beside them.

Environment
===========
The scripts were tested in the following config:
OS: Windows
Python version: 3.10.8
Spacy version: 3.5.3 with en_core_web_lg model installed